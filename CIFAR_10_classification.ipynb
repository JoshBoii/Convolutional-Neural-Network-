{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDfqgiG3H9w3xSDbbqiJyZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoshBoii/Convolutional-Neural-Network-/blob/main/CIFAR_10_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "pFAcDZiT0X3d"
      },
      "outputs": [],
      "source": [
        "#Import necessary libraries and modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from itertools import product\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyper-parameters\n",
        "num_classes = 10\n",
        "batch_size = 128\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "3B_loKC75qHn"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters to tune\n",
        "num_blocks_values = [2, 3, 4]\n",
        "num_convs_values = [1, 2, 3]\n",
        "learning_rate_values = [0.0001, 0.001, 0.01]\n",
        "\n",
        "# Create a list of all hyperparameter combinations\n",
        "hyperparams = list(product(num_blocks_values, num_convs_values, learning_rate_values))"
      ],
      "metadata": {
        "id": "UC80rUspG8dt"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the dataset and create dataloaders\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "DAdDl3d7PPAk"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKvsmJxRPPqO",
        "outputId": "3f6bffe5-6046-4707-a690-3f2c08575344"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "IHnK_zBlPbli"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture - added complexity \n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_convs, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        layers = []\n",
        "        for i in range(num_convs - 1):\n",
        "            layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layers(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_blocks, num_convs, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layers = nn.ModuleList([BasicBlock(self.in_channels, 64, num_convs), \n",
        "                                     BasicBlock(64, 64, num_convs),\n",
        "                                     BasicBlock(64, 64, num_convs)])\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            out = layer(out)\n",
        "\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "x9KE_nfS_MMH"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line `device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")` checks if a GPU with CUDA support is available on your system. If it is available, it will use the GPU (\"cuda\") as the device. If not, it will fall back to using the CPU (\"cpu\"). This allows the code to run on systems with or without GPU support."
      ],
      "metadata": {
        "id": "3oj7ALEoRKLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to train and evaluate the model with a given set of hyperparameters\n",
        "def train_and_evaluate_model(num_blocks, num_convs, learning_rate):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Define the model architecture\n",
        "    model = CNN(num_blocks, num_convs, num_classes).to(device)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Add a learning rate scheduler\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "    # Initialize lists for recording statistics\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    test_accs = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "\n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Forward\n",
        "            scores = model(data)\n",
        "            loss = criterion(scores, targets)\n",
        "\n",
        "            # Backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = scores.max(1)\n",
        "            train_total += targets.size(0)\n",
        "            train_correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # Update loss\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            if (batch_idx+1) % 100 == 0:\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                      .format(epoch+1, num_epochs, batch_idx+1, len(train_loader), loss.item()))\n",
        "\n",
        "        # Record statistics\n",
        "        train_losses.append(train_loss/len(train_loader))\n",
        "        train_acc = 100 * train_correct / train_total\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        # Evaluate model on test set\n",
        "        with torch.no_grad():\n",
        "            test_correct = 0\n",
        "            test_total = 0\n",
        "            for data, targets in test_loader:\n",
        "                data = data.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                scores = model(data)\n",
        "                _, predicted = scores.max(1)\n",
        "                test_total += targets.size(0)\n",
        "                test_correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            test_acc = 100 * test_correct / test_total\n",
        "            test_accs.append(test_acc)\n",
        "            print('Epoch [{}/{}], Test Accuracy: {:.4f}%'\n",
        "                  .format(epoch+1, num_epochs, test_acc))\n",
        "\n",
        "    # Return the final test accuracy\n",
        "    return test_accs[-1]\n"
      ],
      "metadata": {
        "id": "9-ddV10_JVU5"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Device being used:\", torch.cuda.get_device_name(device))\n"
      ],
      "metadata": {
        "id": "1yXyOqMuS_aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search\n",
        "best_accuracy = 0\n",
        "best_hyperparams = None\n",
        "\n",
        "for hyperparam_set in hyperparams:\n",
        "    num_blocks, num_convs, learning_rate = hyperparam_set\n",
        "    accuracy = train_and_evaluate_model(num_blocks, num_convs, learning_rate)\n",
        "    print('Hyperparameters:', hyperparam_set)\n",
        "    print('Accuracy:', accuracy)\n",
        "    print()\n",
        "\n",
        "    # Update best hyperparameters\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_hyperparams = hyperparam_set\n",
        "\n",
        "print('Best hyperparameters:', best_hyperparams)\n",
        "print('Best accuracy:', best_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-Zwi4bLLIh8",
        "outputId": "0e94abcf-592c-480b-99c8-c403d79436e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/391], Loss: 1.9037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the final model using the best hyperparameters\n",
        "best_num_blocks, best_num_convs, best_learning_rate = best_hyperparams\n",
        "final_accuracy = train_and_evaluate_model(best_num_blocks, best_num_convs, best_learning_rate)\n",
        "print('Final accuracy with best hyperparameters:', final_accuracy)\n",
        "\n",
        "# Save the model (optional)\n",
        "torch.save(model.state_dict(), 'best_model.pth')\n"
      ],
      "metadata": {
        "id": "iTdbyCJ5NX8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model (optional)\n",
        "loaded_model = CNN(best_num_blocks, best_num_convs, num_classes).to(device)\n",
        "loaded_model.load_state_dict(torch.load('best_model.pth'))\n",
        "loaded_model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Use the loaded model for inference (optional)\n",
        "with torch.no_grad():\n",
        "    # Example: Get predictions for a single image from the test set\n",
        "    sample_image, sample_label = test_dataset[0]\n",
        "    sample_image = sample_image.unsqueeze(0).to(device)  # Add a batch dimension and move to device\n",
        "    scores = loaded_model(sample_image)\n",
        "    _, predicted_label = scores.max(1)\n",
        "    print('Predicted label:', predicted_label.item())\n",
        "    print('True label:', sample_label)\n"
      ],
      "metadata": {
        "id": "kaTGCPoGNeM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print final test accuracy\n",
        "print('Final Test Accuracy: {:.4f}%'.format(test_accs[-1]))\n",
        "\n",
        "# Save accuracies to file\n",
        "np.savetxt('train_accs.txt', train_accs)\n",
        "np.savetxt('test_accs.txt', test_accs)\n"
      ],
      "metadata": {
        "id": "_GWqdAD9CnDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**END**"
      ],
      "metadata": {
        "id": "pqjjlGM-DIy_"
      }
    }
  ]
}